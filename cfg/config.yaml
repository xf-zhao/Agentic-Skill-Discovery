defaults:
  - _self_
  - env: franka_table
  - override hydra/launcher: local
  - override hydra/output: local

hydra:
  job:
    chdir: True

resume: True
# LLM parameters
# model: gpt-4-0125-preview
model: gpt-3.5-turbo-0125  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
seed: 0
temperature: 1
debug: False
headless: False
max_iterations: 100 # RL Policy training iterations (decrease this to make the feedback loop faster)
num_envs: 1024
memory_requirement: 8
min_gpu_mem: 8
video: False
target_num_skills: 64
failed_tolerance: 128
proposal_batch: 10
task_iterations: 1 # iterate to acquire more variants
n_success_samples: 1 # number of samples to generate success function per iteration
n_reward_samples: 3 # number of samples to generate reward function per iteration
reward_iterations: 1
num_variants: 1 # break if sufficient
task: ''
mission: "Reach Cube A."
precedents: null
# precedents: "R8486375e,R8486375e"

# Weights and Biases
wandb_project: "Zero-Hero" # wandb project if logging with wandb