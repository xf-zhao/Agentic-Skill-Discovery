defaults:
  - _self_
  - env: franka_table
  - exploit: exploit
  - override hydra/launcher: local
  - override hydra/output: local

hydra:
  job:
    chdir: True

resume: True
# LLM parameters
# model: gpt-4-0125-preview
model: gpt-3.5-turbo-0125  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
seed: 0
temperature: 1
proposal:
  model: gpt-4-0125-preview
  target_num_skills: 64
  failed_tolerance: 256
  proposal_batch: 10
design:
  model: gpt-4-0125-preview
  temperature: 0
  seeds:
    - 0
debug: False
headless: True
max_iterations: 2000 # RL Policy training iterations (decrease this to make the feedback loop faster)
num_envs: 4096
memory_requirement: 16
min_gpu: 80 # % of util
video: False
task_iterations: 2 # iterate to acquire more variants
n_success_samples: 3 # number of samples to generate success function per iteration
n_reward_samples: 4 # number of samples to generate reward function per iteration
reward_iterations: 4
num_variants: 9999 # break if sufficient
task: 'Place cube A on top of cube B carefully, aligning their surfaces to stack them.'
precedents: 
  Rabac9e60: "Pick up cube A."
use_wandb: True
wandb_project: "Zero-Hero" # wandb project if logging with wandb