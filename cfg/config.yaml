defaults:
  - _self_
  - env: franka_table
  - override hydra/launcher: local
  - override hydra/output: local

hydra:
  job:
    chdir: True

resume: True
# LLM parameters
# model: gpt-4-0125-preview
model: gpt-3.5-turbo-0125  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
seed: 99
temperature: 1
debug: False
headless: True
max_iterations: 1500 # RL Policy training iterations (decrease this to make the feedback loop faster)
num_envs: 2048
memory_requirement: 12
min_gpu_mem: 12
video: False
target_num_skills: 64
failed_tolerance: 256
proposal_batch: 10
task_iterations: 3 # iterate to acquire more variants
n_success_samples: 3 # number of samples to generate success function per iteration
n_reward_samples: 3 # number of samples to generate reward function per iteration
reward_iterations: 3
num_variants: 1 # break if sufficient
task: 'Reach cube B.'
mission: ''
precedents: null
machine: 'cluster' # local
# precedents: "R8486375e,R8486375e"
# Weights and Biases
wandb_project: "Zero-Hero" # wandb project if logging with wandb