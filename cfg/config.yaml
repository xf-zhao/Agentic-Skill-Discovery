defaults:
  - _self_
  - env: franka_table
  - override hydra/launcher: local
  - override hydra/output: local

hydra:
  job:
    chdir: True

resume: True
# LLM parameters
# model: gpt-4-turbo-preview
model: gpt-3.5-turbo  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
seed: 1
temperature: 0.7
debug: False
num_envs: 2048
max_iterations: 2000 # RL Policy training iterations (decrease this to make the feedback loop faster)
headless: True
video: False
memory_requirement: 4

# Eureka parameters
iteration: 1 # how many iterations of Eureka to run
n_reward_samples: 2 # number of samples to generate reward function per iteration
n_success_samples: 1 # number of samples to generate success function per iteration
num_eval: 4 # number of evaluation episodes to run for the final reward
capture_video: False # whether to capture policy rollout videos

# Weights and Biases
use_wandb: False # whether to use wandb for logging
wandb_username: "" # wandb username if logging with wandb
wandb_project: "" # wandb project if logging with wandb