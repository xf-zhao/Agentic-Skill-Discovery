import os
import wandb
from omegaconf import OmegaConf
from tqdm import tqdm
import logging
import subprocess
import openai
import pandas as pd
import hydra
import re
from zero_hero.task import Database, TaskDatabase
from zero_hero.core import (
    gpt_call,
    wrap_system_message,
    wrap_user_message,
    ZERO_HERO_ROOT_DIR,
    RewardNode,
)
from eurekaplus.utils.extract_task_code import file_to_string


SUBTASKS_PROPOSAL_DEBUG = """
1. REUSE, skill 1.
2. INTRODUCE, Reach cube A.
"""


class SkillDatabase(Database):
    def __init__(
        self,
        store_path="skills.csv",
    ) -> None:
        self.store_path = store_path
        self.load()
        pass

    def load(self):
        store_path = self.store_path
        columns = ["skill", "precedents", "reward"]
        if os.path.exists(store_path):
            df = pd.read_csv(store_path)
        else:
            os.makedirs(os.path.dirname(store_path), exist_ok=True)
            df = pd.DataFrame(columns=columns)
        self.df = df
        return self

    def absorb(self, task_database):
        skills = task_database.skills
        df = pd.DataFrame(
            {
                "skill": skills["command"],
                "precedents": "",
                "variants": skills["variants"],
            }
        )
        self.df = df
        self.save()
        return

    def get_variant(self, index=None, task=None):
        if index is not None:
            variants = self.df.loc[index]["variants"]
        elif task is not None:
            variants = self.df[self.df["skill"] == task]["variants"]
        else:
            raise NotImplementedError
        return variants

    def save(self):
        self.df.to_csv(self.store_path, index=False)
        return

    def render(self):
        df = self.df
        numbered_skills = "\n".join(
            [f"({i+1}) Skill: {row.skill.rstrip('.')}." for i, row in df.iterrows()]
        )
        print(numbered_skills)
        return numbered_skills


class Divider:
    def __init__(self, model="gpt-3.5-turbo-0125", root_dir=None, debug=False) -> None:
        self.model = model
        self.root_dir = root_dir if root_dir is not None else ZERO_HERO_ROOT_DIR
        self.prompt_dir = f"{self.root_dir}/eurekaplus/utils/prompts"
        self.initial_sys = file_to_string(f"{self.prompt_dir}/skill/initial_sys.txt")
        self.initial_user = file_to_string(f"{self.prompt_dir}/skill/initial_user.txt")
        self.debug = debug

    def run(self, mission: str, skill_database: SkillDatabase):
        if self.debug:
            subtasks_proposal = SUBTASKS_PROPOSAL_DEBUG
        else:
            messages = [
                wrap_system_message(
                    self.initial_sys.format(skills=skill_database.render())
                ),
                wrap_user_message(self.initial_user.format(task=mission)),
            ]
            resp = gpt_call(
                messages=messages, model=self.model, n_samples=1, temperature=0
            )
            subtasks_proposal = resp[0]["message"]["content"]
        logging.info(subtasks_proposal)
        subtask_pattern = r"\d+\.\s(.*)"
        subtasks_with_method = re.findall(subtask_pattern, subtasks_proposal)
        subtasks, methods, variants = [], [], []
        for st in subtasks_with_method:
            method, subtask = st.split("] ")
            method = method.strip("[").strip("]").lower()
            if "reuse" in method:
                index = re.search(r"skill\s(\d+).*", subtask).group(1)
                variant = skill_database.get_variant(index=int(index))
                # subtask = skill_database
            else:
                variant = ""
            subtasks.append(subtask)
            methods.append(method)  # introduce, reuse
            variants.append(variant)
        df = pd.DataFrame(
            {
                "subtask": subtasks,
                "method": methods,
                "variants": variants,
                "status": "todo",
            }
        )
        return df


class Conquerer:
    def __init__(self, subtasks) -> None:
        self.df = subtasks
        self.env_name = "franka_table"
        seed = 99
        env_idx = f"E{seed:02d}"
        self.tdb = TaskDatabase(
            store_path=f'{ZERO_HERO_ROOT_DIR}/envs_gpt/tasks/{self.env_name.replace(" ","_")}_{env_idx}.csv'
        )

    def run(self):
        precedents = []
        df = self.df
        subtasks = df["subtask"].values
        homework = [""] * len(subtasks)
        for i, row in tqdm(df.iterrows()):
            subtask = row.subtask
            if row["method"] == "introduce":
                # learn and update
                # precedents =','.join(row.precedents.split(',').strip())
                command = [
                    # "python3",
                    "/data/xufeng/miniconda3/envs/zerohero/bin/python",
                    f"{ZERO_HERO_ROOT_DIR}/learn.py",
                    f'task="{subtask}"',
                    "seed=99",
                ]
                if len(precedents) > 0:
                    precedents_str = ",".join(precedents)
                    command.append(f'precedents="{precedents_str}"')
                print(f"Command to run:\n {command}")
                sp = subprocess.Popen(
                    command,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
                out_str, _ = sp.communicate()
                print(out_str)
                self.tdb.load()
                subtask_homework = self.tdb.get_attr(attr="status", task=subtask)[0]
                homework[i] = subtask_homework
                if subtask_homework == "failed":
                    logging.info(f"Failed to learn! Break at {subtask}.")
                    return subtasks, homework, precedents, False
                elif subtask_homework == "compromised":
                    logging.warning(f"Compromised at subtask: {subtask}")
                else:
                    pass
                variants = self.tdb.get_attr(attr="variants", task=subtask)
            elif row["method"] == "reuse":
                variants = [row["variants"]]
            else:
                raise NotImplementedError
            precedents = [*precedents, *variants]
        return subtasks, homework, precedents, True


@hydra.main(config_path="cfg", config_name="config", version_base="1.1")
def main(cfg):
    openai.api_key = os.getenv("OPENAI_API_KEY")
    model = cfg.model
    cfg.wandb_project = "Zero-Hero-Exploit"
    my_cfg = OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True)
    wandbrun = wandb.init(
        project=cfg.wandb_project,
        config=my_cfg,
    )
    logging.info(cfg)
    logging.info(f"Using LLM: {model}")
    env_name = cfg.env.env_name.lower()
    env_idx = f"E{cfg.seed:02d}"

    tdb = TaskDatabase(
        store_path=f'{ZERO_HERO_ROOT_DIR}/envs_gpt/tasks/{env_name.replace(" ","_")}_{env_idx}.csv',
        target_num_skills=cfg.target_num_skills,
        failed_tolerance=cfg.failed_tolerance,
        proposal_batch=cfg.proposal_batch,
    )

    sdb = SkillDatabase(
        store_path=f'{ZERO_HERO_ROOT_DIR}/envs_gpt/skills/{env_name.replace(" ","_")}_{env_idx}.csv',
    )
    sdb.absorb(tdb)
    divider = Divider(debug=False)
    mission = cfg.mission
    subtasks_df = divider.run(mission, skill_database=sdb)
    conquerer = Conquerer(subtasks=subtasks_df)
    subtasks, homework, precedents, succ = conquerer.run()
    if not succ:
        print(f"Faild to learn mission {mission}. Stuck after {precedents} and ")
    else:
        print(f"Precedents to complete mission {mission} are: {precedents}")
    last_reward_node_idx = precedents.pop(-1)
    rnode = RewardNode(
        idx=last_reward_node_idx,
        precedents=precedents,
        headless=cfg.headless,
        memory_requirement=cfg.memory_requirement,
        min_gpu_mem=cfg.min_gpu_mem,
    ).init()
    playbacks = rnode.play(suffix="_all")
    print(playbacks)
    v_idx, v_path = playbacks["reward_idx"], playbacks["video_path"]
    wandb_video = {f"{v_idx}_all": wandb.Video(v_path, fps=30, format="mp4")}
    wandb_info_table = {
        "subtasks": wandb.Table(
            columns=[i for i in range(len(subtasks))], data=[subtasks, homework]
        ),
        "precedents": wandb.Table(
            columns=[i for i in range(len(precedents))], data=precedents
        ),
    }
    wandbrun.log(
        {
            "success": succ,
            **wandb_info_table,
            **wandb_video,
        }
    )


if __name__ == "__main__":
    main()
